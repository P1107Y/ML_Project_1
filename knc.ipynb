{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Machine Learning Model to predcit the event based on Î¦-OTDR readings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the required libraries wherever and whenever required as per usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of                           file_path  target\n",
      "0        ../trainData/drop/5491.jpg       0\n",
      "1        ../trainData/drop/2712.jpg       0\n",
      "2        ../trainData/drop/1075.jpg       0\n",
      "3        ../trainData/drop/1237.jpg       0\n",
      "4        ../trainData/drop/2854.jpg       0\n",
      "...                             ...     ...\n",
      "20995  ../trainData/qiaoji/2754.jpg       4\n",
      "20996  ../trainData/qiaoji/3925.jpg       4\n",
      "20997  ../trainData/qiaoji/4501.jpg       4\n",
      "20998   ../trainData/qiaoji/252.jpg       4\n",
      "20999  ../trainData/qiaoji/2526.jpg       4\n",
      "\n",
      "[21000 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"images2.csv\", names=[\"file_path\",\"target\"])\n",
    "print(df.describe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "\n",
    "from skimage.filters import prewitt_h,prewitt_v"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting basic features such as mean, std, corr and zero crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_mean(npa):  return np.mean(npa)\n",
    "\n",
    "def img_std(npa):   return np.std(npa)\n",
    "\n",
    "def img_corr(image):\n",
    "    img_med = image.filter(ImageFilter.MedianFilter(size = 3))\n",
    "    return np.corrcoef(image,img_med).mean()\n",
    "\n",
    "def img_zcrs(npa):\n",
    "    zcr = np.mean(npa, axis = 0) - npa.mean().mean()\n",
    "    zero_crossings = np.where(np.diff(np.signbit(zcr)))[0]\n",
    "    return len(zero_crossings)\n",
    "\n",
    "def img_skew(npa):  return pd.DataFrame(npa).skew().mean()\n",
    "\n",
    "def img_kurt(npa):  return pd.DataFrame(npa).kurtosis().mean()\n",
    "\n",
    "def img_ver_edge(npa): return prewitt_v(npa).mean()\n",
    "\n",
    "def img_hor_edge(npa): return prewitt_h(npa).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the features such as number of data points in certain frequency ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_ranges(npa):\n",
    "    col = np.mean(npa, axis = 0)\n",
    "    bt_0_50 = ((50>col) & (col>=0)).sum()\n",
    "    bt_50_100 = ((100>col) & (col>=50)).sum()\n",
    "    bt_100_150 = ((150>col) & (col>=100)).sum()\n",
    "    ab_150 = (col>=150).sum()\n",
    "    return bt_0_50, bt_50_100, bt_100_150, ab_150\n",
    "\n",
    "def stren(npa): \n",
    "    temperory=freq_ranges(npa)\n",
    "    strn=temperory[2]+temperory[3]\n",
    "    return strn\n",
    "    \n",
    "def event(npa):\n",
    "    zcr = np.mean(npa, axis = 0) - 100\n",
    "    ev = len(np.where(np.diff(np.signbit(zcr)))[0])\n",
    "    return ev\n",
    "\n",
    "def img_stren(npa):\n",
    "\n",
    "    if event(npa)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        val=2*stren(npa)/event(npa)\n",
    "        return val\n",
    "\n",
    "def spectral_energy(npa):\n",
    "  mat=npa\n",
    "  total=npa.sum()\n",
    "  x=[]\n",
    "  for i in range(4):\n",
    "    count=0\n",
    "    for j in range((len(mat)//4)*i,(len(mat)//4)*(i+1)):\n",
    "      count+=sum(mat[j])\n",
    "    x.append(count/total)\n",
    "  return x[0],x[1],x[2],x[3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Extraction of features from the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>corr</th>\n",
       "      <th>zcrs</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>event_strength</th>\n",
       "      <th>edge_v</th>\n",
       "      <th>edge_h</th>\n",
       "      <th>x[0]</th>\n",
       "      <th>x[1]</th>\n",
       "      <th>x[2]</th>\n",
       "      <th>x[3]</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.765820</td>\n",
       "      <td>37.987719</td>\n",
       "      <td>0.641946</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.693545</td>\n",
       "      <td>4.235893</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.123381</td>\n",
       "      <td>0.288142</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.298609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.484570</td>\n",
       "      <td>40.607841</td>\n",
       "      <td>0.704699</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.683911</td>\n",
       "      <td>4.448071</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.124027</td>\n",
       "      <td>0.312687</td>\n",
       "      <td>0.314106</td>\n",
       "      <td>0.249180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.393633</td>\n",
       "      <td>38.616103</td>\n",
       "      <td>0.636090</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.581144</td>\n",
       "      <td>3.511482</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.109798</td>\n",
       "      <td>0.266535</td>\n",
       "      <td>0.300964</td>\n",
       "      <td>0.322703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.179883</td>\n",
       "      <td>52.298636</td>\n",
       "      <td>0.582311</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.662758</td>\n",
       "      <td>4.098637</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.093242</td>\n",
       "      <td>0.236650</td>\n",
       "      <td>0.300809</td>\n",
       "      <td>0.369299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.750898</td>\n",
       "      <td>47.866475</td>\n",
       "      <td>0.686309</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.601055</td>\n",
       "      <td>4.052781</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.118435</td>\n",
       "      <td>0.258129</td>\n",
       "      <td>0.284491</td>\n",
       "      <td>0.338945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>41.145313</td>\n",
       "      <td>49.929015</td>\n",
       "      <td>0.486868</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.436900</td>\n",
       "      <td>2.693499</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>-0.002108</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.094429</td>\n",
       "      <td>0.239033</td>\n",
       "      <td>0.285022</td>\n",
       "      <td>0.381517</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>22.244258</td>\n",
       "      <td>40.136412</td>\n",
       "      <td>0.669736</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.632976</td>\n",
       "      <td>3.840018</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.000881</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.141502</td>\n",
       "      <td>0.277087</td>\n",
       "      <td>0.334228</td>\n",
       "      <td>0.247183</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>23.887070</td>\n",
       "      <td>32.084761</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.674582</td>\n",
       "      <td>4.021697</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.115755</td>\n",
       "      <td>0.269571</td>\n",
       "      <td>0.313459</td>\n",
       "      <td>0.301216</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>24.216875</td>\n",
       "      <td>36.220532</td>\n",
       "      <td>0.556774</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.662630</td>\n",
       "      <td>4.064199</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.120955</td>\n",
       "      <td>0.290392</td>\n",
       "      <td>0.315316</td>\n",
       "      <td>0.273337</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20999</th>\n",
       "      <td>52.194961</td>\n",
       "      <td>57.917841</td>\n",
       "      <td>0.365056</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.499545</td>\n",
       "      <td>3.002621</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>0.223020</td>\n",
       "      <td>0.281706</td>\n",
       "      <td>0.401503</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows Ã 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean        std      corr  zcrs      skew  kurtosis  \\\n",
       "0      25.765820  37.987719  0.641946  38.0  1.693545  4.235893   \n",
       "1      24.484570  40.607841  0.704699  18.0  1.683911  4.448071   \n",
       "2      25.393633  38.616103  0.636090  26.0  1.581144  3.511482   \n",
       "3      38.179883  52.298636  0.582311  36.0  1.662758  4.098637   \n",
       "4      32.750898  47.866475  0.686309  24.0  1.601055  4.052781   \n",
       "...          ...        ...       ...   ...       ...       ...   \n",
       "20995  41.145313  49.929015  0.486868  36.0  1.436900  2.693499   \n",
       "20996  22.244258  40.136412  0.669736  10.0  1.632976  3.840018   \n",
       "20997  23.887070  32.084761  0.480300  18.0  1.674582  4.021697   \n",
       "20998  24.216875  36.220532  0.556774   6.0  1.662630  4.064199   \n",
       "20999  52.194961  57.917841  0.365056  52.0  1.499545  3.002621   \n",
       "\n",
       "       event_strength    edge_v    edge_h      x[0]      x[1]      x[2]  \\\n",
       "0            6.000000 -0.000297  0.001941  0.123381  0.288142  0.289867   \n",
       "1            4.000000 -0.000099  0.002135  0.124027  0.312687  0.314106   \n",
       "2            4.500000 -0.000152  0.003218  0.109798  0.266535  0.300964   \n",
       "3            5.142857  0.004713  0.004995  0.093242  0.236650  0.300809   \n",
       "4            3.000000  0.000144  0.003870  0.118435  0.258129  0.284491   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "20995        2.857143 -0.002108  0.005676  0.094429  0.239033  0.285022   \n",
       "20996        2.000000 -0.000881  0.000666  0.141502  0.277087  0.334228   \n",
       "20997        1.200000 -0.000515  0.003082  0.115755  0.269571  0.313459   \n",
       "20998        2.500000  0.000119  0.002145  0.120955  0.290392  0.315316   \n",
       "20999        2.000000 -0.001998  0.009471  0.093771  0.223020  0.281706   \n",
       "\n",
       "           x[3]  target  \n",
       "0      0.298609       0  \n",
       "1      0.249180       0  \n",
       "2      0.322703       0  \n",
       "3      0.369299       0  \n",
       "4      0.338945       0  \n",
       "...         ...     ...  \n",
       "20995  0.381517       4  \n",
       "20996  0.247183       4  \n",
       "20997  0.301216       4  \n",
       "20998  0.273337       4  \n",
       "20999  0.401503       4  \n",
       "\n",
       "[21000 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm = pd.DataFrame( columns = [\"mean\", \"std\", \"corr\", \"zcrs\"] )\n",
    "\n",
    "temp_df = pd.DataFrame( columns = [\"skew\", \"kurtosis\", \"event_strength\"] )\n",
    "\n",
    "dup_df = pd.DataFrame( columns = [\"edge_v\", \"edge_h\"])\n",
    "\n",
    "se_df = pd.DataFrame( columns = [\"x[0]\", \"x[1]\", \"x[2]\", \"x[3]\" ])\n",
    "\n",
    "for imgs in df.file_path:\n",
    "    image = Image.open(imgs)\n",
    "    npa = np.array(image)\n",
    "    \n",
    "    dfm.loc[len(dfm)] = [ img_mean(npa), img_std(npa),img_corr(image), img_zcrs(npa) ]\n",
    "    temp_df.loc[len(temp_df)] = [ img_skew(npa), img_kurt(npa), img_stren(npa)]\n",
    "    dup_df.loc[len(dup_df)] = [img_ver_edge(npa), img_hor_edge(npa)]\n",
    "    list = spectral_energy(npa)\n",
    "    se_df.loc[len(se_df)] = list\n",
    "\n",
    "dfm = pd.concat([dfm, temp_df], axis=1)\n",
    "dfm = pd.concat([dfm, dup_df], axis =1)\n",
    "dfm = pd.concat([dfm, se_df], axis=1)\n",
    "dfm['target'] = df.target\n",
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm.to_csv(\"ML_Features.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataframe into the required features and target to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfm.drop('target',axis='columns')\n",
    "y = dfm.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing we import StandardScaler to remove the mean and scales each feature/variable to unit variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20061701,  0.10082043,  1.44455375, ...,  0.44499414,\n",
       "        -0.44067398, -0.18257587],\n",
       "       [-0.28937809,  0.26485498,  1.84970224, ...,  0.99050104,\n",
       "         0.39962908, -0.74755305],\n",
       "       [-0.22640102,  0.14016085,  1.40674595, ..., -0.0352248 ,\n",
       "        -0.05596038,  0.09282124],\n",
       "       ...,\n",
       "       [-0.33077106, -0.26873829,  0.40092621, ...,  0.03225498,\n",
       "         0.37721028, -0.15278363],\n",
       "       [-0.3079232 , -0.00981549,  0.89466378, ...,  0.49499257,\n",
       "         0.44160167, -0.47143098],\n",
       "       [ 1.63031299,  1.34855951, -0.34311493, ..., -1.00232305,\n",
       "        -0.72361861,  0.99350207]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "tab = PrettyTable()\n",
    "tab.title = 'ML Model Scores with different splits'\n",
    "tab.field_names = ['Split Ratio', 'KNNClassfier']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use train_test_split to split the data for training the model and for testing the model,\\\n",
    "we can give paramaters such as test_size to determine how much of the data is given to testing and training, \\\n",
    "then import the required model from respective library and create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "splits = [0.3]\n",
    "\n",
    "for split in splits:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = split, random_state = 40)\n",
    "\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=12)\n",
    "    model_knn.fit(X_train, y_train)\n",
    "    #knnscore = model_knn.score(X_test, y_test)\n",
    "    scoresknn = cross_val_score(KNeighborsClassifier(), X_test, y_test, cv=5)\n",
    "    scoresknn = scoresknn.mean()\n",
    "\n",
    "    tab.add_row([f\"Split: {split}\", scoresknn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "k_range = [i for i in range(1,31)]\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "  \n",
    "# defining parameter range\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.09881473, 0.08895016, 0.09731913, 0.09060154, 0.09305835,\n",
       "        0.08658895, 0.0907443 , 0.09310908, 0.09273505, 0.07584534,\n",
       "        0.08731503, 0.07114725, 0.08157592, 0.08375349, 0.08156261,\n",
       "        0.09514108, 0.08962579, 0.08155389, 0.09369144, 0.06707001,\n",
       "        0.04891782, 0.09658628, 0.12459111, 0.12828035, 0.08077908,\n",
       "        0.08690872, 0.08080263, 0.09576321, 0.093151  , 0.09238477]),\n",
       " 'std_fit_time': array([0.02409419, 0.01190949, 0.00510038, 0.01271734, 0.01158377,\n",
       "        0.01501548, 0.00425716, 0.00296049, 0.00246642, 0.01320921,\n",
       "        0.01376805, 0.01594747, 0.01929396, 0.01252897, 0.01266689,\n",
       "        0.00788408, 0.01055962, 0.00988156, 0.00113511, 0.02412557,\n",
       "        0.00429909, 0.02606737, 0.01558872, 0.01245963, 0.01647412,\n",
       "        0.0124253 , 0.01852716, 0.00577151, 0.002481  , 0.01001431]),\n",
       " 'mean_score_time': array([0.59044347, 0.62337914, 0.64968433, 0.65008616, 0.68789582,\n",
       "        0.68894968, 0.73787985, 0.76120553, 0.752773  , 0.73840857,\n",
       "        0.75139666, 0.76419492, 0.79015007, 0.81594753, 0.76118445,\n",
       "        0.84492259, 0.90419817, 0.87949882, 0.91375113, 0.64647293,\n",
       "        0.50660448, 0.97910872, 1.07686367, 1.18532333, 0.72632127,\n",
       "        0.86939454, 0.87251835, 1.01752176, 0.97873993, 1.01814885]),\n",
       " 'std_score_time': array([0.0986751 , 0.02104053, 0.03935345, 0.03098515, 0.06743346,\n",
       "        0.04041873, 0.03823891, 0.09141838, 0.06698152, 0.09673756,\n",
       "        0.06455361, 0.08311934, 0.11502919, 0.07000261, 0.07901407,\n",
       "        0.0230341 , 0.04524061, 0.03564044, 0.006529  , 0.23212248,\n",
       "        0.08211271, 0.15405995, 0.10012986, 0.0438353 , 0.0503449 ,\n",
       "        0.10835374, 0.13942855, 0.03282681, 0.05622925, 0.04655334]),\n",
       " 'param_n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 1},\n",
       "  {'n_neighbors': 2},\n",
       "  {'n_neighbors': 3},\n",
       "  {'n_neighbors': 4},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 6},\n",
       "  {'n_neighbors': 7},\n",
       "  {'n_neighbors': 8},\n",
       "  {'n_neighbors': 9},\n",
       "  {'n_neighbors': 10},\n",
       "  {'n_neighbors': 11},\n",
       "  {'n_neighbors': 12},\n",
       "  {'n_neighbors': 13},\n",
       "  {'n_neighbors': 14},\n",
       "  {'n_neighbors': 15},\n",
       "  {'n_neighbors': 16},\n",
       "  {'n_neighbors': 17},\n",
       "  {'n_neighbors': 18},\n",
       "  {'n_neighbors': 19},\n",
       "  {'n_neighbors': 20},\n",
       "  {'n_neighbors': 21},\n",
       "  {'n_neighbors': 22},\n",
       "  {'n_neighbors': 23},\n",
       "  {'n_neighbors': 24},\n",
       "  {'n_neighbors': 25},\n",
       "  {'n_neighbors': 26},\n",
       "  {'n_neighbors': 27},\n",
       "  {'n_neighbors': 28},\n",
       "  {'n_neighbors': 29},\n",
       "  {'n_neighbors': 30}],\n",
       " 'split0_test_score': array([0.74455782, 0.73095238, 0.77517007, 0.76972789, 0.78333333,\n",
       "        0.78027211, 0.78367347, 0.78571429, 0.79081633, 0.78809524,\n",
       "        0.79285714, 0.78809524, 0.78741497, 0.78707483, 0.78911565,\n",
       "        0.78911565, 0.79217687, 0.78945578, 0.78741497, 0.78673469,\n",
       "        0.79047619, 0.79013605, 0.78877551, 0.79013605, 0.78707483,\n",
       "        0.78741497, 0.78707483, 0.78605442, 0.78605442, 0.78231293]),\n",
       " 'split1_test_score': array([0.73877551, 0.71802721, 0.76666667, 0.76190476, 0.78367347,\n",
       "        0.78401361, 0.79047619, 0.78979592, 0.79965986, 0.79965986,\n",
       "        0.79965986, 0.79965986, 0.80034014, 0.79727891, 0.80340136,\n",
       "        0.79727891, 0.79659864, 0.7962585 , 0.79761905, 0.79421769,\n",
       "        0.79251701, 0.79421769, 0.79489796, 0.79387755, 0.79489796,\n",
       "        0.79285714, 0.79455782, 0.79319728, 0.79081633, 0.79183673]),\n",
       " 'split2_test_score': array([0.75646259, 0.7377551 , 0.77346939, 0.77142857, 0.79081633,\n",
       "        0.79047619, 0.79455782, 0.79489796, 0.79897959, 0.80068027,\n",
       "        0.79795918, 0.79659864, 0.79557823, 0.79829932, 0.79965986,\n",
       "        0.79931973, 0.7962585 , 0.79693878, 0.80102041, 0.80034014,\n",
       "        0.80068027, 0.79421769, 0.79931973, 0.79795918, 0.8037415 ,\n",
       "        0.80068027, 0.80306122, 0.79965986, 0.79693878, 0.79421769]),\n",
       " 'split3_test_score': array([0.74455782, 0.73401361, 0.77619048, 0.77176871, 0.79217687,\n",
       "        0.78571429, 0.79047619, 0.79183673, 0.79047619, 0.78571429,\n",
       "        0.78469388, 0.78979592, 0.78605442, 0.79081633, 0.79081633,\n",
       "        0.79013605, 0.79047619, 0.7914966 , 0.78911565, 0.78877551,\n",
       "        0.79115646, 0.79081633, 0.79115646, 0.78707483, 0.78537415,\n",
       "        0.78469388, 0.78571429, 0.78469388, 0.78469388, 0.78503401]),\n",
       " 'split4_test_score': array([0.76156463, 0.75034014, 0.78945578, 0.7962585 , 0.80646259,\n",
       "        0.80306122, 0.80306122, 0.80952381, 0.81598639, 0.81530612,\n",
       "        0.81190476, 0.8170068 , 0.81496599, 0.81598639, 0.81666667,\n",
       "        0.81190476, 0.81496599, 0.81564626, 0.81292517, 0.81394558,\n",
       "        0.81258503, 0.80918367, 0.80918367, 0.81258503, 0.81054422,\n",
       "        0.81258503, 0.81258503, 0.8122449 , 0.81292517, 0.81258503]),\n",
       " 'mean_test_score': array([0.74918367, 0.73421769, 0.77619048, 0.77421769, 0.79129252,\n",
       "        0.78870748, 0.79244898, 0.79435374, 0.79918367, 0.79789116,\n",
       "        0.79741497, 0.79823129, 0.79687075, 0.79789116, 0.79993197,\n",
       "        0.79755102, 0.79809524, 0.79795918, 0.79761905, 0.79680272,\n",
       "        0.79748299, 0.79571429, 0.79666667, 0.79632653, 0.79632653,\n",
       "        0.79564626, 0.79659864, 0.79517007, 0.79428571, 0.79319728]),\n",
       " 'std_test_score': array([0.00845455, 0.01044301, 0.00741777, 0.01158741, 0.00839688,\n",
       "        0.00789057, 0.0063539 , 0.00815078, 0.0092567 , 0.01056811,\n",
       "        0.00892065, 0.01030652, 0.0104647 , 0.00995013, 0.00992218,\n",
       "        0.00818987, 0.00875571, 0.00928266, 0.00918997, 0.00978647,\n",
       "        0.00839137, 0.00694278, 0.00720382, 0.00890975, 0.00964068,\n",
       "        0.01007722, 0.01010611, 0.0100841 , 0.01025926, 0.01061966]),\n",
       " 'rank_test_score': array([29, 30, 27, 28, 25, 26, 24, 21,  2,  6, 11,  3, 12,  6,  1,  9,  4,\n",
       "         5,  8, 13, 10, 18, 14, 16, 17, 19, 15, 20, 22, 23])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.098815</td>\n",
       "      <td>0.024094</td>\n",
       "      <td>0.590443</td>\n",
       "      <td>0.098675</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.744558</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.756463</td>\n",
       "      <td>0.744558</td>\n",
       "      <td>0.761565</td>\n",
       "      <td>0.749184</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088950</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.623379</td>\n",
       "      <td>0.021041</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "      <td>0.730952</td>\n",
       "      <td>0.718027</td>\n",
       "      <td>0.737755</td>\n",
       "      <td>0.734014</td>\n",
       "      <td>0.750340</td>\n",
       "      <td>0.734218</td>\n",
       "      <td>0.010443</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.097319</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.649684</td>\n",
       "      <td>0.039353</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.775170</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.773469</td>\n",
       "      <td>0.776190</td>\n",
       "      <td>0.789456</td>\n",
       "      <td>0.776190</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090602</td>\n",
       "      <td>0.012717</td>\n",
       "      <td>0.650086</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.769728</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.796259</td>\n",
       "      <td>0.774218</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.093058</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>0.687896</td>\n",
       "      <td>0.067433</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.792177</td>\n",
       "      <td>0.806463</td>\n",
       "      <td>0.791293</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.086589</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.688950</td>\n",
       "      <td>0.040419</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>0.780272</td>\n",
       "      <td>0.784014</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.803061</td>\n",
       "      <td>0.788707</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.090744</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>0.737880</td>\n",
       "      <td>0.038239</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.794558</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.803061</td>\n",
       "      <td>0.792449</td>\n",
       "      <td>0.006354</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.093109</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.761206</td>\n",
       "      <td>0.091418</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.789796</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.791837</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.794354</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.092735</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.752773</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.799660</td>\n",
       "      <td>0.798980</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.815986</td>\n",
       "      <td>0.799184</td>\n",
       "      <td>0.009257</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.075845</td>\n",
       "      <td>0.013209</td>\n",
       "      <td>0.738409</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.788095</td>\n",
       "      <td>0.799660</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.815306</td>\n",
       "      <td>0.797891</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.087315</td>\n",
       "      <td>0.013768</td>\n",
       "      <td>0.751397</td>\n",
       "      <td>0.064554</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.799660</td>\n",
       "      <td>0.797959</td>\n",
       "      <td>0.784694</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>0.008921</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.015947</td>\n",
       "      <td>0.764195</td>\n",
       "      <td>0.083119</td>\n",
       "      <td>12</td>\n",
       "      <td>{'n_neighbors': 12}</td>\n",
       "      <td>0.788095</td>\n",
       "      <td>0.799660</td>\n",
       "      <td>0.796599</td>\n",
       "      <td>0.789796</td>\n",
       "      <td>0.817007</td>\n",
       "      <td>0.798231</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.081576</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.790150</td>\n",
       "      <td>0.115029</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.787415</td>\n",
       "      <td>0.800340</td>\n",
       "      <td>0.795578</td>\n",
       "      <td>0.786054</td>\n",
       "      <td>0.814966</td>\n",
       "      <td>0.796871</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.083753</td>\n",
       "      <td>0.012529</td>\n",
       "      <td>0.815948</td>\n",
       "      <td>0.070003</td>\n",
       "      <td>14</td>\n",
       "      <td>{'n_neighbors': 14}</td>\n",
       "      <td>0.787075</td>\n",
       "      <td>0.797279</td>\n",
       "      <td>0.798299</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.815986</td>\n",
       "      <td>0.797891</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.081563</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.761184</td>\n",
       "      <td>0.079014</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.803401</td>\n",
       "      <td>0.799660</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.799932</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.095141</td>\n",
       "      <td>0.007884</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.797279</td>\n",
       "      <td>0.799320</td>\n",
       "      <td>0.790136</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.797551</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.089626</td>\n",
       "      <td>0.010560</td>\n",
       "      <td>0.904198</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>0.792177</td>\n",
       "      <td>0.796599</td>\n",
       "      <td>0.796259</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.814966</td>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.081554</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>0.879499</td>\n",
       "      <td>0.035640</td>\n",
       "      <td>18</td>\n",
       "      <td>{'n_neighbors': 18}</td>\n",
       "      <td>0.789456</td>\n",
       "      <td>0.796259</td>\n",
       "      <td>0.796939</td>\n",
       "      <td>0.791497</td>\n",
       "      <td>0.815646</td>\n",
       "      <td>0.797959</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.093691</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.913751</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>0.787415</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.801020</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.812925</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.067070</td>\n",
       "      <td>0.024126</td>\n",
       "      <td>0.646473</td>\n",
       "      <td>0.232122</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>0.786735</td>\n",
       "      <td>0.794218</td>\n",
       "      <td>0.800340</td>\n",
       "      <td>0.788776</td>\n",
       "      <td>0.813946</td>\n",
       "      <td>0.796803</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.048918</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.506604</td>\n",
       "      <td>0.082113</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.792517</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.791156</td>\n",
       "      <td>0.812585</td>\n",
       "      <td>0.797483</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.096586</td>\n",
       "      <td>0.026067</td>\n",
       "      <td>0.979109</td>\n",
       "      <td>0.154060</td>\n",
       "      <td>22</td>\n",
       "      <td>{'n_neighbors': 22}</td>\n",
       "      <td>0.790136</td>\n",
       "      <td>0.794218</td>\n",
       "      <td>0.794218</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.809184</td>\n",
       "      <td>0.795714</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.124591</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>1.076864</td>\n",
       "      <td>0.100130</td>\n",
       "      <td>23</td>\n",
       "      <td>{'n_neighbors': 23}</td>\n",
       "      <td>0.788776</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.799320</td>\n",
       "      <td>0.791156</td>\n",
       "      <td>0.809184</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.128280</td>\n",
       "      <td>0.012460</td>\n",
       "      <td>1.185323</td>\n",
       "      <td>0.043835</td>\n",
       "      <td>24</td>\n",
       "      <td>{'n_neighbors': 24}</td>\n",
       "      <td>0.790136</td>\n",
       "      <td>0.793878</td>\n",
       "      <td>0.797959</td>\n",
       "      <td>0.787075</td>\n",
       "      <td>0.812585</td>\n",
       "      <td>0.796327</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.080779</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.726321</td>\n",
       "      <td>0.050345</td>\n",
       "      <td>25</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "      <td>0.787075</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.803741</td>\n",
       "      <td>0.785374</td>\n",
       "      <td>0.810544</td>\n",
       "      <td>0.796327</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.086909</td>\n",
       "      <td>0.012425</td>\n",
       "      <td>0.869395</td>\n",
       "      <td>0.108354</td>\n",
       "      <td>26</td>\n",
       "      <td>{'n_neighbors': 26}</td>\n",
       "      <td>0.787415</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.784694</td>\n",
       "      <td>0.812585</td>\n",
       "      <td>0.795646</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.080803</td>\n",
       "      <td>0.018527</td>\n",
       "      <td>0.872518</td>\n",
       "      <td>0.139429</td>\n",
       "      <td>27</td>\n",
       "      <td>{'n_neighbors': 27}</td>\n",
       "      <td>0.787075</td>\n",
       "      <td>0.794558</td>\n",
       "      <td>0.803061</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.812585</td>\n",
       "      <td>0.796599</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.095763</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>1.017522</td>\n",
       "      <td>0.032827</td>\n",
       "      <td>28</td>\n",
       "      <td>{'n_neighbors': 28}</td>\n",
       "      <td>0.786054</td>\n",
       "      <td>0.793197</td>\n",
       "      <td>0.799660</td>\n",
       "      <td>0.784694</td>\n",
       "      <td>0.812245</td>\n",
       "      <td>0.795170</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.093151</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.978740</td>\n",
       "      <td>0.056229</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_neighbors': 29}</td>\n",
       "      <td>0.786054</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.796939</td>\n",
       "      <td>0.784694</td>\n",
       "      <td>0.812925</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.010259</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.092385</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>1.018149</td>\n",
       "      <td>0.046553</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_neighbors': 30}</td>\n",
       "      <td>0.782313</td>\n",
       "      <td>0.791837</td>\n",
       "      <td>0.794218</td>\n",
       "      <td>0.785034</td>\n",
       "      <td>0.812585</td>\n",
       "      <td>0.793197</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.098815      0.024094         0.590443        0.098675   \n",
       "1        0.088950      0.011909         0.623379        0.021041   \n",
       "2        0.097319      0.005100         0.649684        0.039353   \n",
       "3        0.090602      0.012717         0.650086        0.030985   \n",
       "4        0.093058      0.011584         0.687896        0.067433   \n",
       "5        0.086589      0.015015         0.688950        0.040419   \n",
       "6        0.090744      0.004257         0.737880        0.038239   \n",
       "7        0.093109      0.002960         0.761206        0.091418   \n",
       "8        0.092735      0.002466         0.752773        0.066982   \n",
       "9        0.075845      0.013209         0.738409        0.096738   \n",
       "10       0.087315      0.013768         0.751397        0.064554   \n",
       "11       0.071147      0.015947         0.764195        0.083119   \n",
       "12       0.081576      0.019294         0.790150        0.115029   \n",
       "13       0.083753      0.012529         0.815948        0.070003   \n",
       "14       0.081563      0.012667         0.761184        0.079014   \n",
       "15       0.095141      0.007884         0.844923        0.023034   \n",
       "16       0.089626      0.010560         0.904198        0.045241   \n",
       "17       0.081554      0.009882         0.879499        0.035640   \n",
       "18       0.093691      0.001135         0.913751        0.006529   \n",
       "19       0.067070      0.024126         0.646473        0.232122   \n",
       "20       0.048918      0.004299         0.506604        0.082113   \n",
       "21       0.096586      0.026067         0.979109        0.154060   \n",
       "22       0.124591      0.015589         1.076864        0.100130   \n",
       "23       0.128280      0.012460         1.185323        0.043835   \n",
       "24       0.080779      0.016474         0.726321        0.050345   \n",
       "25       0.086909      0.012425         0.869395        0.108354   \n",
       "26       0.080803      0.018527         0.872518        0.139429   \n",
       "27       0.095763      0.005772         1.017522        0.032827   \n",
       "28       0.093151      0.002481         0.978740        0.056229   \n",
       "29       0.092385      0.010014         1.018149        0.046553   \n",
       "\n",
       "   param_n_neighbors               params  split0_test_score  \\\n",
       "0                  1   {'n_neighbors': 1}           0.744558   \n",
       "1                  2   {'n_neighbors': 2}           0.730952   \n",
       "2                  3   {'n_neighbors': 3}           0.775170   \n",
       "3                  4   {'n_neighbors': 4}           0.769728   \n",
       "4                  5   {'n_neighbors': 5}           0.783333   \n",
       "5                  6   {'n_neighbors': 6}           0.780272   \n",
       "6                  7   {'n_neighbors': 7}           0.783673   \n",
       "7                  8   {'n_neighbors': 8}           0.785714   \n",
       "8                  9   {'n_neighbors': 9}           0.790816   \n",
       "9                 10  {'n_neighbors': 10}           0.788095   \n",
       "10                11  {'n_neighbors': 11}           0.792857   \n",
       "11                12  {'n_neighbors': 12}           0.788095   \n",
       "12                13  {'n_neighbors': 13}           0.787415   \n",
       "13                14  {'n_neighbors': 14}           0.787075   \n",
       "14                15  {'n_neighbors': 15}           0.789116   \n",
       "15                16  {'n_neighbors': 16}           0.789116   \n",
       "16                17  {'n_neighbors': 17}           0.792177   \n",
       "17                18  {'n_neighbors': 18}           0.789456   \n",
       "18                19  {'n_neighbors': 19}           0.787415   \n",
       "19                20  {'n_neighbors': 20}           0.786735   \n",
       "20                21  {'n_neighbors': 21}           0.790476   \n",
       "21                22  {'n_neighbors': 22}           0.790136   \n",
       "22                23  {'n_neighbors': 23}           0.788776   \n",
       "23                24  {'n_neighbors': 24}           0.790136   \n",
       "24                25  {'n_neighbors': 25}           0.787075   \n",
       "25                26  {'n_neighbors': 26}           0.787415   \n",
       "26                27  {'n_neighbors': 27}           0.787075   \n",
       "27                28  {'n_neighbors': 28}           0.786054   \n",
       "28                29  {'n_neighbors': 29}           0.786054   \n",
       "29                30  {'n_neighbors': 30}           0.782313   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.738776           0.756463           0.744558   \n",
       "1            0.718027           0.737755           0.734014   \n",
       "2            0.766667           0.773469           0.776190   \n",
       "3            0.761905           0.771429           0.771769   \n",
       "4            0.783673           0.790816           0.792177   \n",
       "5            0.784014           0.790476           0.785714   \n",
       "6            0.790476           0.794558           0.790476   \n",
       "7            0.789796           0.794898           0.791837   \n",
       "8            0.799660           0.798980           0.790476   \n",
       "9            0.799660           0.800680           0.785714   \n",
       "10           0.799660           0.797959           0.784694   \n",
       "11           0.799660           0.796599           0.789796   \n",
       "12           0.800340           0.795578           0.786054   \n",
       "13           0.797279           0.798299           0.790816   \n",
       "14           0.803401           0.799660           0.790816   \n",
       "15           0.797279           0.799320           0.790136   \n",
       "16           0.796599           0.796259           0.790476   \n",
       "17           0.796259           0.796939           0.791497   \n",
       "18           0.797619           0.801020           0.789116   \n",
       "19           0.794218           0.800340           0.788776   \n",
       "20           0.792517           0.800680           0.791156   \n",
       "21           0.794218           0.794218           0.790816   \n",
       "22           0.794898           0.799320           0.791156   \n",
       "23           0.793878           0.797959           0.787075   \n",
       "24           0.794898           0.803741           0.785374   \n",
       "25           0.792857           0.800680           0.784694   \n",
       "26           0.794558           0.803061           0.785714   \n",
       "27           0.793197           0.799660           0.784694   \n",
       "28           0.790816           0.796939           0.784694   \n",
       "29           0.791837           0.794218           0.785034   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.761565         0.749184        0.008455               29  \n",
       "1            0.750340         0.734218        0.010443               30  \n",
       "2            0.789456         0.776190        0.007418               27  \n",
       "3            0.796259         0.774218        0.011587               28  \n",
       "4            0.806463         0.791293        0.008397               25  \n",
       "5            0.803061         0.788707        0.007891               26  \n",
       "6            0.803061         0.792449        0.006354               24  \n",
       "7            0.809524         0.794354        0.008151               21  \n",
       "8            0.815986         0.799184        0.009257                2  \n",
       "9            0.815306         0.797891        0.010568                6  \n",
       "10           0.811905         0.797415        0.008921               11  \n",
       "11           0.817007         0.798231        0.010307                3  \n",
       "12           0.814966         0.796871        0.010465               12  \n",
       "13           0.815986         0.797891        0.009950                6  \n",
       "14           0.816667         0.799932        0.009922                1  \n",
       "15           0.811905         0.797551        0.008190                9  \n",
       "16           0.814966         0.798095        0.008756                4  \n",
       "17           0.815646         0.797959        0.009283                5  \n",
       "18           0.812925         0.797619        0.009190                8  \n",
       "19           0.813946         0.796803        0.009786               13  \n",
       "20           0.812585         0.797483        0.008391               10  \n",
       "21           0.809184         0.795714        0.006943               18  \n",
       "22           0.809184         0.796667        0.007204               14  \n",
       "23           0.812585         0.796327        0.008910               16  \n",
       "24           0.810544         0.796327        0.009641               17  \n",
       "25           0.812585         0.795646        0.010077               19  \n",
       "26           0.812585         0.796599        0.010106               15  \n",
       "27           0.812245         0.795170        0.010084               20  \n",
       "28           0.812925         0.794286        0.010259               22  \n",
       "29           0.812585         0.793197        0.010620               23  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = pd.DataFrame(grid.cv_results_)\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data='knc_0.3.csv'\n",
    "dftest.to_csv(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 15}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#List Hyperparameters that we want to tune.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing all the scores of the Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = []\n",
    "for i in range(30,35):\n",
    "    C.append(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':('rbf','poly'), 'C':C}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "GridSearchCV(estimator=SVC(),\n",
    "             param_grid={'C':C, 'kernel': ('rbf','poly')})\n",
    "sorted(clf.cv_results_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dftest = pd.DataFrame(clf.cv_results_)\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_data='file_data_new.csv'\n",
    "#dftest.to_csv(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "| ML Model Scores with different splits  |\n",
      "+---------------+------------------------+\n",
      "|  Split Ratio  |      KNNClassfier      |\n",
      "+---------------+------------------------+\n",
      "|   Split: 0.3  |   0.7676190476190475   |\n",
      "+---------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(tab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Seaborn library to plot the confusion matrix to check the truth matrix i.e, \\\n",
    "how many correct predictions are there and for how many the model was confused to predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the last model to plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 919   27    0    2  301]\n",
      " [  26  992  165   30   72]\n",
      " [   0  213 1011   17   11]\n",
      " [   0  115   66 1046   23]\n",
      " [ 143   46    1    3 1071]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.845     0.736     0.786      1249\n",
      "           1      0.712     0.772     0.741      1285\n",
      "           2      0.813     0.808     0.810      1252\n",
      "           3      0.953     0.837     0.891      1250\n",
      "           4      0.725     0.847     0.781      1264\n",
      "\n",
      "    accuracy                          0.800      6300\n",
      "   macro avg      0.809     0.800     0.802      6300\n",
      "weighted avg      0.809     0.800     0.802      6300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_test, y_pred_knn, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'KNNClassifier')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "sn.heatmap(cm_knn, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title('KNNClassifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "961786f95080325d0e6977461e5717a534591674bb0d89c293c3449765d31696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
